results <- 3+5-6
results
library(ggplot2)
ggplot(data = mpg,
aes(x = displ, y = hwy)) +
geom_point()
data(mpg, package = "ggplot2")
head(mpg)
summary(mpg)
help(mpg)
txt <- c(text1 = "This is $10 in 999 different ways,\n up and down; left and right!",
text2 = "@koheiw7 working: on #quanteda 2day\t4ever, http://textasdata.com?page=123.")
tokens(txt)
library("quanteda")
corp_uk <- corpus(data_char_ukimmig2010)
summary(corp_uk)
docvars(corp_uk, "Party") <- names(data_char_uimmig2010)
docvars(corp_uk, "Party") <- names(data_char_ukimmig2010)
docvars(copr_uk, "Year") <- 2010
docvars(corp_uk, "Year") <- 2010
summary(corp_uk)
require(readtext)
print(data_corpus_inaugural)
as.character(data_corpus_inaugural)[2]
as.character(data_corpus_inaugural)[3]
summary(data_corpus_inaugural, n = 5)
summary(data_corpus_inaugural, n = 10)
dat_json <- readtext("social_media/zombies/tweets.json")
tokeninfo <- summary(data_corpus_inaugural)
tokeninfo$Year <- docvars(data_corpus_inaugural, "Year")
with(tokeninfo, plot (Year, Tokens, type = "b", pch = 19, cex = .7))
tokeninfo[which.max(tokeninfo$Tokens)]
tokeninfo[which.max(tokeninfo$Tokens), ]
corp1 <- head(data_corpus_inaugural, 2)
corp2 <- tail(data_corpus_inaugural, 2)
corp3 <- corp1 + corp2
summary(corp3)
summary(corpus_subset(data_corpus_inaugural, Year > 1990))
summary(corpus_subset(data_corpus_inaugural, President == "Adams"))
data_tokens_inaugural <- tokens(data_corpus_inaugural)
kwic(data_tokens_inaugural, pattern = "terror")
kwic(data_tokens_inaugural, pattern = "terror", valuetype = "regex")
kwic(data_tokens_inaugural, pattern = "communist*")
kwic(data_tokens_inaugural, pattern = phrase ("United States")) |> head()
head(docvars(data_corpus_inaugural))
txt <- c(text1 = "This is $10 in 999 different ways,\n up and down; left and right!",
text2 = "@koheiw7 working: on #quanteda 2day\t4ever, http://textasdata.com?page=123.")
tokens(txt)
tokens(txt, remove_numbers = TRUE, remove_punct = TRUE)
tokens(txt, remove_numbers = FALSE, remove-punct = TRUE)
tokens(txt, remove_numbers = FALSE, remove_punct = TRUE)
tokens(txt, remove_numbers = TRUE,  remove_punct = FALSE)
tokens(txt, remove_numbers = FALSE, remove_punct = FALSE, remove_separators = FALSE)
install.packages("keyATM")
install.packages("keyATM")
install.packages("tidyverse")
install.packages("quanteda")
library(keyATM)
library(tidyverse)
library(quanteda)
data <- read_csv("success_survey - The Definition of Academic Success Survey_November 11, 2025_08.47.csv.numbers")
data <- read_csv("success_survey - The Definition of Academic Success Survey_November 11, 2025_08.47")
data <- read_csv("success_survey.csv")
data <- read_csv("/Users/miloscomputer/Downloads/success_survey.csv")
data <- read_csv ("success_survey - The Definition of Academic Success Survey_November 11, 2025_08.47.csv")
data <- read_csv("success_survey1.csv")
glimpse(data)
data <- data %>%
mutate()
data <- data %>%
mutate(definition_text = tolowere(definition_text), definition_text = str_replace_all(definition_text, "[^a-z\\s]", " "), definition_text = str_squish(definition_text) )
data <- data %>%
+ mutate(definition_text = tolower(definition_text), definition_text = str_replace_all(definition_text, "[^a-z\\s]", " "), definition_text = str_squish(definition_text) )
data <- data %>%
filter(!is.na(definition_text), definition_text != "")
names(data)
data <- data %>%
mutate(
definition = tolower(definition),
definition = str_replace_all(definition, "[^a-z\\s]", " "),
definition = str_squish(definition)
)
data <- data %>%
filter(!is.na(definition), definition != "")
data <- data %>%
mutate(
academicgoals = tolower(academicgoals),
academicgoals = str_replace_all(academicgoals, "[^a-z\\s]", " "),
academicgoals = str_squish(academicgoals)
)
filter(!is.na(academicgoals), academicgoals != "")
data <- data%>%
filter(!is.na(academicgoals), academicgoals != "")
data <- data%>%
mutate(
describeacademicgoals = tolower(describeacademicgoals),
describeacademicgoals = str_replace_all(describeacademicgoals, "[^a-z\\s]", " "),
describeacademicgoals = str_squish(describeacademicgoals)
)
data <- data %>%
filter(!is.na(describeacademicgoals), describeacademicgoals != "")
data <- data %>%
mutate(
resourceswhy = tolower(resourceswhy),
resourceswhy = str_replace_all(resourceswhy, "[^a-z\\s]", " "),
resourceswhy = str_squish(resourceswhy)
)
data <- data %>%
filter(!is.na(resourceswhy), resourceswhy != "")
data <- data%>%
mutate(
futureimpact = tolower(futureimpact),
futureimpact = str_replace_all(futureimpact, "[^a-z\\s]", " "),
futureimpact = str_squish(futureimpact)
)
data <- data %>%
filter(!is.na(futureimpact), futureimpact != "")
corpus <- corpus(data, text_field = "definition")
toks <- tokens(
corpus,
remove_punct = TRUE,
remove_numbers = TRUE
) %>%
tokens_remove(stopwords("en"))
dfm_success <- dfm(toks)
keywords <- list(
grades   = c("grade", "grades", "gpa", "test", "score", "scores", "sat", "exam"),
future   = c("college", "career", "job", "future", "opportunity", "admission"),
learning = c("learning", "curiosity", "understand", "mastery", "improve", "growth", "challenge"),
)
keywords <- list(
grades = c("grade", "grades", "exams", "exam", "test", "score"),
future = c("college", "career", "profession", "job", "future", "opportunity", "admission")
learning = c("learning", "curiosity", "understand", "mastery", "improve", "growtj", "challenge"),
keywords <- list(
grades = c("grade", "grades", "exams", "exam", "test", "score"),
future = c("college", "career", "profession", "job", "future", "opportunity", "admission"),
learning = c("learning", "curiosity", "understand", "mastery", "improve", "growth", "challenge"),
balance  = c("happy", "happiness", "mental", "balance", "stress", "wellbeing", "burnout")
)
keyatm_docs <- keyATM_read(dfm_success)
set.seed(123)
model <- keyATM(
docs = keyatm_docs$docs,
vocab = keyatm_docs$vocab,
K = 10,
model = "base",
keywords = keywords,
options = list(seed = 123,
iter = 2000,
burnin = 500)
)
set.seed(123)
model <- keyATM(
docs = keyatm_docs,
model = "base",
no_keyword_topics = 5,
keywords = keywords,
options = list(
seed = 123,
iterations = 2000,
verbose = TRUE,
store_theta = TRUE
)
)
dfm_success <- drm(toks)
vocab <- keyatm_docs$vocab
sapply(keywords,function(kw) intersect(kw, vocab))
keywords_clean <- lapply(keywords, function(kw) intersect (kw, vocab))
keywords_clean
keywords_clean <- keywords_clean[sapply(keywords_clean, length) > 0]
model <- keyATM(
docs = keyatm_docs,
model = "base",
no_keyword_topics = 5,
keywords = keywords_clean,
options = list(seed = 123, iter = 2000, burnin = 500)
)
library(factoextra)
